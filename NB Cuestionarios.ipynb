{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as est√°ndar de Python\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from io import BytesIO\n",
    "from functools import lru_cache\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "from typing import List, Union\n",
    "\n",
    "# Librer√≠as de terceros\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import boto3\n",
    "from matplotlib.colors import LinearSegmentedColormap, SymLogNorm\n",
    "import textwrap\n",
    "\n",
    "# Librer√≠as para manejo de documentos Word\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.text.paragraph import Paragraph\n",
    "from docx.oxml import parse_xml, OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT, WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.table import WD_TABLE_ALIGNMENT, WD_ALIGN_VERTICAL\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "\n",
    "# Librerias propias\n",
    "import openIA_analisis_conclusiones as OA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Segoe UI Emoji'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexion y descarga de Query desde Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_para_analizar(proyecto=None, instituciones=None, grade=None, career=None, educacion=None, grade_section=None, genero=None, etario=None):\n",
    "    '''\tGenera una lista que contiene los elementos del dataframe que se van a analizar y la cuales deberan ser ingresadas por el usuario '''\n",
    "    lista = []\n",
    "    if proyecto is True:\n",
    "        lista.append('project_id')\n",
    "    if instituciones is True:\n",
    "        lista.append('educative_institution')\n",
    "    if grade is True:\n",
    "        lista.append('grade')\n",
    "    if career is True:\n",
    "        lista.append('career')\n",
    "    if educacion is True:\n",
    "        lista.append('educational_level')\n",
    "    if grade_section is True:\n",
    "        lista.append('grade_section')\n",
    "    if genero is True:\n",
    "        lista.append('genero')\n",
    "    if etario is True:\n",
    "        lista.append('rango_etario')\n",
    "    return lista\n",
    "\n",
    "# Diccionario de mapeo\n",
    "mapeo_variables = {\n",
    "    'project_id': 'Proyecto ID',\n",
    "    'educative_institution': 'Instituci√≥n Educativa',\n",
    "    'grade': 'Grado',\n",
    "    'career': 'Carrera',\n",
    "    'educational_level': 'Nivel Educativo',\n",
    "    'grade_section': 'Secci√≥n',\n",
    "    'genero': 'G√©nero',\n",
    "    'rango_etario': 'Rango Etario',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables a cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Filtros hacia la query\n",
    "project_id = \"74\" # 72,73,74 (en el front se deberia mostrar un lista de los proyectos)\n",
    "tipo_test = 'evs' # (En el front se deberia mostrar una lista de los tipos de test)\n",
    "IA = True # si esto se pone en true el informe demora unos 20min\n",
    "\n",
    "lista_graficos=lista_para_analizar(\n",
    "    proyecto=None,\n",
    "    instituciones=True,\n",
    "    grade=True,\n",
    "    career=None,\n",
    "    educacion=None,\n",
    "    grade_section=None,\n",
    "    genero=True,\n",
    "    etario=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Definir el filtro de tipo_test seg√∫n el valor de la variable\n",
    "test = tipo_test.lower()  # Aseguramos consistencia en min√∫sculas\n",
    "if test == \"evs\":\n",
    "    filtro_tipo_test = \"'cuestionario de entrada', 'cuestionario de salida'\"\n",
    "elif test == \"evm\":\n",
    "    filtro_tipo_test = \"'cuestionario de entrada', 'cuestionario medio'\"\n",
    "elif test == \"mvs\":\n",
    "    filtro_tipo_test = \"'cuestionario medio', 'cuestionario de salida'\"\n",
    "else:\n",
    "    filtro_tipo_test = f\"'{tipo_test}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar Tiempo\n",
    "start_time_consulta= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Consulta CTAS completada.\n",
      "üîó Resultados guardados en: s3://aws-athena-query-results-us-east-1-158862062418/python_ale/1764280244/\n",
      "‚úÖ Datos cargados en el DataFrame.\n",
      "üóëÔ∏è Tabla python_table_1764280244 eliminada de Athena.\n"
     ]
    }
   ],
   "source": [
    "# Crear los clientes de Athena y S3\n",
    "athena = boto3.client('athena', region_name='us-east-1')\n",
    "s3 = boto3.client('s3', region_name='us-east-1')\n",
    "bucket_output = 'aws-athena-query-results-us-east-1-158862062418'\n",
    "\n",
    "# Generamos un path √∫nico para la salida en Parquet, usando el timestamp\n",
    "timestamp = int(time.time())\n",
    "parquet_output_path = f's3://{bucket_output}/python_ale/{timestamp}/'\n",
    "\n",
    "query = f''' \n",
    "WITH \n",
    "activos_por_proyecto AS (\n",
    "  select\n",
    "    ee.b2b_project_id,\n",
    "    count(distinct ee.student_id) as inscriptos_activos\n",
    "  from\n",
    "    enrollment_enrolment ee\n",
    "    left join projects p on (p.id = ee.b2b_project_id)\n",
    "  where p.id in ({project_id}) and ee.state <> 'cancel' and ee.state <> 'inactive'\n",
    "  group by 1\n",
    "),\n",
    "\n",
    "activos_por_institucion AS (\n",
    "  select\n",
    "    ee.b2b_project_id,\n",
    "    ee.institution,\n",
    "    count(distinct ee.student_id) as inscriptos_activos\n",
    "  from\n",
    "    enrollment_enrolment ee\n",
    "    \n",
    "  where ee.b2b_project_id in ({project_id}) and ee.state <> 'cancel' and ee.state <> 'inactive'\n",
    "  group by 1,2\n",
    "),\n",
    "\n",
    "activos_por_grado AS (\n",
    "  select\n",
    "    ee.b2b_project_id,\n",
    "    ee.grade,\n",
    "    count(distinct ee.student_id) as inscriptos_activos\n",
    "  from\n",
    "    enrollment_enrolment ee\n",
    "    \n",
    "  where ee.b2b_project_id in ({project_id}) and ee.state <> 'cancel' and ee.state <> 'inactive'\n",
    "  group by 1,2\n",
    "),\n",
    "\n",
    "BASE AS (\n",
    "   SELECT DISTINCT\n",
    "     me.moodle_id moodle_user_id\n",
    "   --, 'No aplica' tipo_estandarizacion\n",
    "   , 'Moodle' origen\n",
    "   --, CONCAT(CAST(ss.id AS varchar), '-', CAST(p.id AS varchar)) identificador_unico\n",
    "   --, me.role moodle_user_role\n",
    "   , ss.id student_id\n",
    "   --, CONCAT(ss.first_name, ' ', ss.last_name) student_name\n",
    "   , ee.institution educative_institution\n",
    "   , ee.grade grade\n",
    "   , concat(ee.grade,'+', ee.group_section) grade_section\n",
    "   , ee.career career\n",
    "   , ee.educational_level educational_level\n",
    "   , DATE_DIFF('year', ss.birthdate, p.operative_start_date) age \n",
    "   , ss.gender genero\n",
    "   , ipp.inscriptos_activos activos_por_proyecto\n",
    "   , ipi.inscriptos_activos activos_por_educative_institution\n",
    "   , ipg.inscriptos_activos activos_por_grade\n",
    "   , p.id project_id\n",
    "   --, p.type project_type\n",
    "   , p.name project_name\n",
    "   --, 'Grupo CTC' tipo_grupo\n",
    "   , ce.course_id moodle_course_id\n",
    "   , rr.id room_id\n",
    "   --, rr.name room_name\n",
    "   , ce.unique_id evaluation_unique_id\n",
    "   , ce.name evaluation_name\n",
    "   --, cer.attempt_time_finish response_time_finished\n",
    "   --, cer.attempt_state attempt_state\n",
    "   --, cer.attempt_id\n",
    "   , ceq.name question_name\n",
    "   , ceq.tag tag_question\n",
    "   , ceq.question_id question_id\n",
    "   , ceq.question_name question\n",
    "   , cer.answer answer\n",
    "   , cer.right_answer right_answer\n",
    "   , ce.tag AS tipo_test\n",
    "\n",
    "   FROM\n",
    "   moodle_enrollment me\n",
    "   LEFT JOIN moodle_course_evaluations ce ON (me.course_id = ce.course_id)\n",
    "   LEFT JOIN moodle_course_evaluation_questions ceq ON (ce.unique_id = ceq.unique_id) AND ((ceq.question_name <> 'label') OR (ceq.question_name IS NULL))\n",
    "   LEFT JOIN moodle_course_evaluation_responses cer ON ((cer.unique_id = ceq.unique_id) AND (ceq.question_id = cer.question_id) AND (me.moodle_id = cer.moodle_id) AND (ce.type <> 'assign')  AND (cer.attempt_time_finish IS NOT NULL))\n",
    "   INNER JOIN room_room rr ON (rr.course_mdl_id = me.course_id)\n",
    "   LEFT JOIN student_student ss ON (ss.user_mdl_id = me.moodle_id)\n",
    "   LEFT JOIN room_room_students rrs ON ((rrs.student_id = ss.id) AND (rrs.room_id = rr.id))\n",
    "   LEFT JOIN enrollment_enrolment ee ON (((ee.group_id = rr.group_id) OR (ee.room_id = rr.id)) AND (ee.student_id = ss.id) AND (ee.state <> 'cancel') AND (ee.state <> 'inactive'))\n",
    "   LEFT JOIN projects p ON (p.id = ee.b2b_project_id)\n",
    "   left JOIN activos_por_proyecto ipp ON (ipp.b2b_project_id = p.id)\n",
    "   left join activos_por_institucion ipi ON (ipi.institution = ee.institution and ipi.b2b_project_id=ee.b2b_project_id)\n",
    "   left join activos_por_grado ipg ON (ipg.grade= ee.grade and ipg.b2b_project_id=ee.b2b_project_id)\n",
    "\n",
    "   WHERE (p.id in ({project_id}) and (me.role = 'student'))\n",
    "\n",
    "   ) \n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  BASE b\n",
    "WHERE \n",
    "(\n",
    "  (b.answer IS NOT NULL) AND (trim(BOTH FROM b.answer) <> '') AND \n",
    "  b.project_id in ({project_id}) AND b.tipo_test IN ({filtro_tipo_test})\n",
    "  \n",
    ")\n",
    "\n",
    "'''\n",
    "\n",
    "# Query para guardar el resultado en un archivo Parquet\n",
    "ctas_query = f\"\"\"\n",
    "CREATE TABLE python_table_{timestamp}\n",
    "WITH (\n",
    "  format = 'PARQUET',\n",
    "  external_location = '{parquet_output_path}',\n",
    "  write_compression = 'SNAPPY'\n",
    ") AS\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta CTAS\n",
    "response = athena.start_query_execution(\n",
    "    QueryString=ctas_query,\n",
    "    QueryExecutionContext={'Database': 'datalake'},\n",
    "    ResultConfiguration={'OutputLocation': f's3://{bucket_output}/'}\n",
    ")\n",
    "\n",
    "# Obtener el ID de ejecuci√≥n y esperar a que termine\n",
    "query_execution_id = response['QueryExecutionId']\n",
    "while True:\n",
    "    result = athena.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "    state = result['QueryExecution']['Status']['State']\n",
    "    if state in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "        break\n",
    "    time.sleep(2)\n",
    "\n",
    "if state == 'FAILED':\n",
    "    print(result['QueryExecution']['Status'].get('StateChangeReason'))\n",
    "\n",
    "if state == 'SUCCEEDED':\n",
    "    print(\"‚úÖ Consulta CTAS completada.\")\n",
    "    print(f\"üîó Resultados guardados en: {parquet_output_path}\")\n",
    "    df = pd.read_parquet(parquet_output_path, engine='pyarrow')\n",
    "    print(\"‚úÖ Datos cargados en el DataFrame.\")\n",
    "    \n",
    "    # Eliminar los archivos Parquet de S3 despu√©s de cargarlos en el DataFrame\n",
    "    try:\n",
    "        # Extraer el prefijo del path S3\n",
    "        prefix = f'python_ale/{timestamp}er/'\n",
    "        \n",
    "        # Listar todos los objetos en el prefijo\n",
    "        objects = s3.list_objects_v2(Bucket=bucket_output, Prefix=prefix)\n",
    "        \n",
    "        if 'Contents' in objects:\n",
    "            # Crear lista de objetos a borrar\n",
    "            delete_keys = [{'Key': obj['Key']} for obj in objects['Contents']]\n",
    "            \n",
    "            # Borrar los objetos\n",
    "            s3.delete_objects(\n",
    "                Bucket=bucket_output,\n",
    "                Delete={'Objects': delete_keys}\n",
    "            )\n",
    "            print(f\"üóëÔ∏è Se eliminaron {len(delete_keys)} archivos Parquet de S3\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al eliminar archivos de S3: {str(e)}\")\n",
    "    \n",
    "\n",
    "    # 3Ô∏è‚É£ Eliminar la tabla en Athena\n",
    "    try:\n",
    "        drop_query = f\"DROP TABLE IF EXISTS datalake.python_table_{timestamp};\"\n",
    "        drop_resp = athena.start_query_execution(\n",
    "            QueryString=drop_query,\n",
    "            QueryExecutionContext={'Database': 'datalake'},\n",
    "            ResultConfiguration={'OutputLocation': f's3://{bucket_output}/'}  # Athena exige un OutputLocation aunque no genere archivos\n",
    "        )\n",
    "        drop_qid = drop_resp['QueryExecutionId']\n",
    "        # Esperar a que se complete el DROP\n",
    "        while True:\n",
    "            drop_status = athena.get_query_execution(QueryExecutionId=drop_qid)['QueryExecution']['Status']['State']\n",
    "            if drop_status in ['SUCCEEDED', 'FAILED', 'CANCELLED']:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if drop_status == 'SUCCEEDED':\n",
    "            print(f\"üóëÔ∏è Tabla python_table_{timestamp} eliminada de Athena.\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Fall√≥ el DROP TABLE con estado: {drop_status}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al eliminar la tabla en Athena: {e}\")\n",
    "\n",
    "else:\n",
    "    raise Exception(result['QueryExecution']['Status'].get('StateChangeReason'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_consulta= time.time()\n",
    "time_consulta= end_time_consulta - start_time_consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para normalizar el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "\n",
    "    if pd.isna(texto):\n",
    "        return ''\n",
    "    # Reemplaza tabuladores, retornos de carro y saltos de l√≠nea por un espacio\n",
    "    texto = re.sub(r'[\\t\\r\\n]', ' ', str(texto))\n",
    "    # Reemplaza m√∫ltiples espacios por uno solo\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "    return texto.strip()\n",
    "\n",
    "def ajustar_titulo(titulo, largo_primera_linea=44, largo_otras_lineas=40, max_lineas=2):\n",
    "\n",
    "    # Si solo se permite una l√≠nea, truncar y rellenar\n",
    "    if max_lineas == 1:\n",
    "        if len(titulo) > largo_primera_linea:\n",
    "            return titulo[:largo_primera_linea - 3] + \"...\"\n",
    "        return titulo.center(largo_primera_linea)\n",
    "\n",
    "    # Separar la primera l√≠nea con el largo espec√≠fico\n",
    "    if len(titulo) <= largo_primera_linea:\n",
    "        linea1 = titulo.center(largo_primera_linea)\n",
    "        return linea1\n",
    "    else:\n",
    "        linea1 = titulo[:largo_primera_linea]\n",
    "        resto = titulo[largo_primera_linea:]\n",
    "\n",
    "    # Envolver el resto en l√≠neas m√°s cortas\n",
    "    lineas_extra = textwrap.wrap(resto.strip(), width=largo_otras_lineas)\n",
    "\n",
    "    # Limitar la cantidad de l√≠neas totales\n",
    "    lineas_extra = lineas_extra[:max_lineas - 1]\n",
    "    \n",
    "    # Si hay m√°s texto que lo permitido, truncar la √∫ltima l√≠nea\n",
    "    if len(lineas_extra) == (max_lineas - 1) and len(titulo) > len(linea1) + sum(len(l) for l in lineas_extra):\n",
    "        if len(lineas_extra[-1]) > largo_otras_lineas - 3:\n",
    "            lineas_extra[-1] = lineas_extra[-1][:largo_otras_lineas - 3] + \"...\"\n",
    "\n",
    "    # Rellenar las l√≠neas\n",
    "    linea1 = linea1.center(largo_primera_linea)\n",
    "    lineas_extra = [l.center(largo_otras_lineas) for l in lineas_extra]\n",
    "\n",
    "    return \"\\n\".join([linea1] + lineas_extra)\n",
    "\n",
    "def ajustar_etiquetas(texto, max_length=30):\n",
    "    \"\"\"Ajusta etiquetas largas dividi√©ndolas en l√≠neas y truncando si es necesario.\"\"\"\n",
    "    if len(texto) <= max_length:\n",
    "        return texto\n",
    "    # Dividir en l√≠neas de m√°ximo 30 caracteres\n",
    "    lineas = textwrap.fill(texto, width=max_length, max_lines=2, placeholder=\"...\").split('\\n')\n",
    "    return '\\n'.join(lineas)\n",
    "\n",
    "def extract_number_text(answer: str):\n",
    "    '''Esta funcion separa la parte numerica y la string'''\n",
    "    _pattern = re.compile(r'^\\s*(\\d+)(?:[\\.\\)\\-\\:\\s]+)(.*)$')\n",
    "    answer = str(answer).strip()\n",
    "    m = _pattern.match(answer)\n",
    "    if m:\n",
    "        numero = m.group(1)\n",
    "        texto  = m.group(2).strip()\n",
    "        return numero, texto\n",
    "    # si no coincide, devolvemos None y el texto completo\n",
    "    return None, answer\n",
    "\n",
    "def normalize_answer(row):\n",
    "    if pd.notnull(row['Number']):\n",
    "        question = row['question']\n",
    "        number = row['Number']\n",
    "        standard_text = mapping.get((question, number), row['Text'])\n",
    "        return f\"{number}. {standard_text}\"\n",
    "    return row['answer']\n",
    "\n",
    "def normalize_question(row):\n",
    "    question = row['question']\n",
    "    tag = row['tag_question']\n",
    "    standard_text = mapping.get(tag, question)\n",
    "    return standard_text\n",
    "\n",
    "def clasificar_tipo_pregunta(respuesta):\n",
    "    if pd.isna(respuesta) or not isinstance(respuesta, str):\n",
    "        return \"Abierta\"\n",
    "    \n",
    "    # 1) Limpiar espacios\n",
    "    respuesta_limpia = respuesta.strip()\n",
    "    baja = respuesta_limpia.lower()\n",
    "    \n",
    "    # 2) Verdadero/Falso como categ√≥ricas\n",
    "    if baja in {\"verdadero\", \"falso\"}:\n",
    "        return \"Categorica\"\n",
    "    \n",
    "    # 3) Si no hay ';', es abierta o categ√≥rica simple seg√∫n prefijo\n",
    "    if ';' not in respuesta_limpia:\n",
    "        if re.match(r'^(\\d+\\.\\s*|[A-Z][\\-\\)])', respuesta_limpia):\n",
    "            return \"Categorica\"\n",
    "        else:\n",
    "            return \"Abierta\"\n",
    "    \n",
    "    # 4) Con ';', buscamos MULTISELECCION ESTRUCTURADA:\n",
    "    patrones_multiseleccion = [\n",
    "        r'\\b\\d+\\.\\s+[^\\;]+(?:;\\s*\\d+\\.\\s+[^\\;]+)+',     # 1. ...; 2. ...\n",
    "        r'\\b[A-Z]\\)\\s+[^\\;]+(?:;\\s*[A-Z]\\)\\s+[^\\;]+)+', # A) ...; B) ...\n",
    "        r'\\b[A-Z]-\\s+[^\\;]+(?:;\\s*[A-Z]-\\s+[^\\;]+)+'    # A- ...; B- ...\n",
    "    ]\n",
    "    for patron in patrones_multiseleccion:\n",
    "        if re.search(patron, respuesta_limpia):\n",
    "            return \"Categorica Multiseleccion\"\n",
    "    \n",
    "    # 5) Si arranca como categ√≥rica pero no multiselecci√≥n:\n",
    "    if re.match(r'^(\\d+\\.\\s*|[A-Z][\\-\\)])', respuesta_limpia):\n",
    "        return \"Categorica\"\n",
    "    \n",
    "    # 6) Lo que quede: abierta\n",
    "    return \"Abierta\"\n",
    "\n",
    "def consolidar_tipo_pregunta(series_tipos):\n",
    "    \"\"\"\n",
    "    Serie de valores: [\"Abierta\", \"Categorica\", \"Categorica Multiseleccion\"].\n",
    "    Devuelve:\n",
    "      - \"Categorica Multiseleccion\" si al menos una respuesta es multiselecci√≥n.\n",
    "      - \"Categorica\" si todas las respuestas son categ√≥ricas.\n",
    "      - \"Abierta\" en cualquier otro caso (incluye mixtas o que contengan abiertas).\n",
    "    \"\"\"\n",
    "    tipos = set(series_tipos)\n",
    "    if \"Categorica Multiseleccion\" in tipos:\n",
    "        return \"Categorica Multiseleccion\"\n",
    "    elif tipos == {\"Categorica\"}:\n",
    "        return \"Categorica\"\n",
    "    else:\n",
    "        return \"Abierta\"\n",
    "\n",
    "def extraer_numero(texto):\n",
    "    \"\"\"\n",
    "    Intenta extraer un n√∫mero entero al inicio del texto, justo antes de un punto.\n",
    "    Retorna el n√∫mero si se encuentra o None si no hay coincidencia.\n",
    "    \"\"\"\n",
    "    # Se utiliza una expresi√≥n regular que busca d√≠gitos seguidos de un punto al inicio del string\n",
    "    m = re.match(r'\\s*(\\d+)\\.', str(texto))\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return None\n",
    "\n",
    "def un_tag_una_pregunta(dataframe: pd.DataFrame):\n",
    "    '''Crear un diccionario con la primera pregunta por cada tag_question '''\n",
    "\n",
    "    primera_pregunta_por_tag = (\n",
    "        dataframe.groupby('tag_question')['question']\n",
    "        .first()\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Reemplazar todas las preguntas con la seleccionada para ese tag_question\n",
    "    dataframe['question'] = dataframe['tag_question'].map(primera_pregunta_por_tag)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def renombrar_tipo_test(tipo_test):\n",
    "    renombrar_test = {\n",
    "        'cuestionario de entrada': 'Cuestionario de entrada',\n",
    "        'cuestionario medio': 'Cuestionario medio',\n",
    "        'cuestionario de salida': 'Cuestionario de salida',\n",
    "        'examen de casos inicial': 'Ex. casos inicial',\n",
    "        'examen de casos final': 'Ex. casos final',\n",
    "        'examen final': 'Ex. final',\n",
    "        'cuestionario de satisfacci√≥n modular': 'Satisfacci√≥n Modular',\n",
    "        'cuestionario de satisfacci√≥n final': 'Satisfacci√≥n Final',\n",
    "    }\n",
    "    return renombrar_test.get(tipo_test, 'Otro')  # Devuelve Otro si no est√° en el diccionario\n",
    "\n",
    "def ordenar_tipo_test(tipo_test):\n",
    "    orden_test = {\n",
    "        'cuestionario de entrada': 1,\n",
    "        'cuestionario medio': 2,\n",
    "        'cuestionario de salida': 3,\n",
    "        'examen de casos inicial': 4,\n",
    "        'examen de casos final': 5,\n",
    "        'examen final': 6,\n",
    "        'cuestionario de satisfacci√≥n modular': 7,\n",
    "        'cuestionario de satisfacci√≥n final': 8,\n",
    "    }\n",
    "    return orden_test.get(tipo_test, 6)  # Devuelve 6 si no est√° en el diccionario\n",
    "\n",
    "def ordenar_tag(tag_question):\n",
    "    orden_tag = {\n",
    "        \"nombre\": 1,\n",
    "        \"genero\": 2,\n",
    "        \"correo_personal\": 3,\n",
    "        \"celular\": 4,\n",
    "        \"celular_de\": 5,\n",
    "        \"tipo_documento\": 6,\n",
    "        \"documento\": 7,\n",
    "        \"nacimiento\": 8,\n",
    "        \"etnia\": 9,\n",
    "        \"nacionalidad\": 10,\n",
    "        \"estrato_socioeconomico\": 11,\n",
    "        \"nivel_educativo_familia\": 12,\n",
    "        \"trabajar_ayuda_casa\": 13,\n",
    "        \"cuidar_ayuda_casa\": 14,\n",
    "        \"interes_tecnologia\": 15,\n",
    "        \"dispositivos\": 16,\n",
    "        \"forma_conectividad\": 17,\n",
    "        \"uso_tecnologia_dia_a_dia\": 18,\n",
    "        \"uso_tecnologia_a_futuro\": 19,\n",
    "        \"planes_futuro\": 20,\n",
    "        \"abandonar_estudios\": 21,\n",
    "        \"motivo_abandonar_estudios\": 22,\n",
    "        \"programas_educativos\": 23,\n",
    "        \"prioridad_programas_educativos\": 24,\n",
    "        \"trabajo\": 25,\n",
    "        \"intereses_futuro\": 26,\n",
    "        \"apoyo_financiero\": 27,\n",
    "        \"financiamiento\": 28,\n",
    "        \"cv\": 29,\n",
    "        \"cv_experiencia_laboral\": 30,\n",
    "        \"empresas\": 31,\n",
    "        \"sitios_busqueda_laboral\": 32,\n",
    "        \"retos_mercado_laboral\": 33,\n",
    "        \"actividades_ultimo_anio\": 34,\n",
    "        \"fuentes_informacion\": 35,\n",
    "        \"fuente_informacion_otros\": 36,\n",
    "        \"motivacion_familia\": 37,\n",
    "        \"motivacion_familia_quienes\": 38,\n",
    "        \"apoyo_econ_familia_estudio\": 39,\n",
    "        \"actividades_profesores\": 40,\n",
    "        \"apoyo_metas_prof_familia\": 41,\n",
    "        \"ayuda_familiar_trabajos\": 42,\n",
    "        \"motivacion_familiar_trabajo\": 43,\n",
    "        \"motivacion_familiar_emprender\": 44,\n",
    "        \"motivacion_profesores_metas\": 45,\n",
    "        # Competencias\n",
    "        'innovacion':46, \n",
    "        'analisis':47,\n",
    "        'critico':48,\n",
    "        'comunicacion':49,\n",
    "        'autogestion':50,\n",
    "        'equipo':51,\n",
    "    }\n",
    "    return orden_tag.get(tag_question, 52)  # Devuelve 52 si no est√° en el diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_por_cluster(df, cluster): \n",
    "    '''grade | educative_institution'''\n",
    "    df_cluster = (\n",
    "        df.groupby(['project_id', 'project_name', cluster, 'tipo_test'])\n",
    "        .agg(\n",
    "            Activos=(f'activos_por_{cluster}', 'max'),  # M√°ximo de inscritos por proyecto\n",
    "            Respuestas=('student_id', 'nunique')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Calcular el porcentaje de respuestas por tipo de test\n",
    "    df_cluster['% Respuestas del'] = round((df_cluster['Respuestas'] / df_cluster['Activos']) * 100, 0)\n",
    "\n",
    "    for p in df.project_id.unique(): \n",
    "        \n",
    "        tabla_cluster_project=df_cluster[df_cluster['project_id']==p]\n",
    "        pname=tabla_cluster_project['project_name'].unique()[0]\n",
    "        # Crear una tabla pivotada para mostrar los datos por tipo de test\n",
    "        df_cluster_pivot = tabla_cluster_project.pivot_table(\n",
    "            index=[cluster, 'Activos'],\n",
    "            columns='tipo_test',\n",
    "            values=['% Respuestas del'],\n",
    "            aggfunc='first'\n",
    "        ).sort_values('Activos', ascending=False).reset_index()\n",
    "\n",
    "        # Aplanar los nombres de las columnas\n",
    "        df_cluster_pivot.columns = [' '.join(col).strip() if isinstance(col, tuple) else col.lower() for col in df_cluster_pivot.columns]\n",
    "\n",
    "        # Reemplazar NaN con 0 antes de convertir a entero\n",
    "        \n",
    "        df_cluster_pivot = df_cluster_pivot.fillna(0)\n",
    "\n",
    "        for c in df_cluster_pivot.columns:\n",
    "            if df_cluster_pivot[c].dtype == 'float64':  # Verificar si la columna es de tipo float\n",
    "                # Primero redondear (para porcentajes) y luego convertir a entero\n",
    "                df_cluster_pivot[c] = df_cluster_pivot[c].round().astype(int)\n",
    "\n",
    "            if '%' in c: \n",
    "                df_cluster_pivot[c] = df_cluster_pivot[c].astype(str)\n",
    "                df_cluster_pivot[c] = df_cluster_pivot[c] + '%'\n",
    "                \n",
    "    return df_cluster_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_aplico2():\n",
    "    from difflib import get_close_matches\n",
    "\n",
    "    # Desde aca en adelante es el c√≥digo para hacer hacer el match de tag y pregunta\n",
    "    mapping_df = pd.read_excel(r'C:\\Users\\boatt\\Downloads\\Lista de tag.xlsx')\n",
    "\n",
    "    # 1) Cargar el DataFrame y la lista de preguntas\n",
    "    df_question=df[['question']].drop_duplicates()\n",
    "    df_question.reset_index(drop=True, inplace=True)\n",
    "    mapping_df = pd.read_excel(r'C:\\Users\\boatt\\Downloads\\Lista de tag.xlsx')\n",
    "\n",
    "    # 2) Funci√≥n de fuzzy matching\n",
    "    def match_question(q, choices, cutoff=0.6):\n",
    "        \"\"\"\n",
    "        Devuelve la mejor coincidencia de 'q' dentro de la lista 'choices',\n",
    "        si la similitud es >= cutoff; si no, devuelve None.\n",
    "        \"\"\"\n",
    "        matches = get_close_matches(q, choices, n=1, cutoff=cutoff)\n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    # 3) Aplicar el matching y hacer merge\n",
    "    df_mapping = mapping_df[['# final', 'seccion', 'tag', 'dimension', 'Pregunta final']].rename(columns={'Pregunta final':'question_match'})\n",
    "\n",
    "    # Para cada pregunta buscamos la ‚ÄúPregunta final‚Äù m√°s parecida\n",
    "    df_question['question_match'] = df_question['question'].apply(lambda x: match_question(x, mapping_df['Pregunta final']))\n",
    "\n",
    "    # Hacemos el merge por la columna auxiliar question_match\n",
    "    df_question = df_question.merge(df_mapping, on='question_match', how='left')\n",
    "    df_question.rename(columns={'# final':'orden'}, inplace=True)\n",
    "\n",
    "    df=df.merge(df_question, on='question', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para trabajar el Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo documento\n",
    "doc = Document()\n",
    "# Configurar p√°gina en tama√±o A4 (21 x 29.7 cm = 8.27 x 11.69 inches)\n",
    "section = doc.sections[0]\n",
    "section.page_height = Inches(11.69)\n",
    "section.page_width = Inches(8.27)\n",
    "\n",
    "# M√°rgenes (por ejemplo, 1 pulgada a cada lado)\n",
    "section.top_margin = Inches(1)\n",
    "section.bottom_margin = Inches(1)\n",
    "section.left_margin = Inches(1)\n",
    "section.right_margin = Inches(1)\n",
    "\n",
    "\n",
    "def agregar_titulo(doc, texto, nivel):\n",
    "    # Paleta de colores corporativos sobrios\n",
    "    COLOR_TITULO = RGBColor(0x2E, 0x3F, 0x5F)  # Azul marino oscuro\n",
    "    COLOR_SUBTITULO = RGBColor(0x4F, 0x4F, 0x4F)  # Gris oscuro\n",
    "\n",
    "    if nivel == 1:\n",
    "        # T√≠tulo principal - Nivel 1\n",
    "        titulo = doc.add_heading(level=1)\n",
    "        run = titulo.add_run(texto.upper())\n",
    "        run.font.name = 'Lora'\n",
    "        run.font.size = Pt(14)\n",
    "        run.font.bold = True\n",
    "        run.font.color.rgb = COLOR_TITULO\n",
    "        titulo.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "        titulo.paragraph_format.space_before = Pt(18)\n",
    "        titulo.paragraph_format.space_after = Pt(12)\n",
    "        \n",
    "        # Agregar l√≠nea decorativa inferior\n",
    "        p = titulo._element\n",
    "        pPr = p.get_or_add_pPr()\n",
    "        pBdr = OxmlElement('w:pBdr')\n",
    "        pPr.append(pBdr)\n",
    "        bottom = OxmlElement('w:bottom')\n",
    "        bottom.set(qn('w:val'), 'single')\n",
    "        bottom.set(qn('w:sz'), '8')\n",
    "        bottom.set(qn('w:space'), '1')\n",
    "        bottom.set(qn('w:color'), '2E3F5F')\n",
    "        pBdr.append(bottom)\n",
    "\n",
    "    elif nivel == 2:\n",
    "        # Subt√≠tulo importante - Nivel 2\n",
    "        titulo = doc.add_heading(level=2)\n",
    "        run = titulo.add_run(texto)\n",
    "        run.font.name = 'Lora'\n",
    "        run.font.size = Pt(12)\n",
    "        run.font.bold = True\n",
    "        run.font.color.rgb = COLOR_SUBTITULO\n",
    "        titulo.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
    "        titulo.paragraph_format.space_before = Pt(14)\n",
    "        titulo.paragraph_format.space_after = Pt(8)\n",
    "        \n",
    "        # Subrayado decorativo\n",
    "        p = titulo._element\n",
    "        pPr = p.get_or_add_pPr()\n",
    "        pBdr = OxmlElement('w:pBdr')\n",
    "        pPr.append(pBdr)\n",
    "        bottom = OxmlElement('w:bottom')\n",
    "        bottom.set(qn('w:val'), 'single')\n",
    "        bottom.set(qn('w:sz'), '6')\n",
    "        bottom.set(qn('w:space'), '1')\n",
    "        bottom.set(qn('w:color'), 'D3D3D3')\n",
    "        pBdr.append(bottom)\n",
    "\n",
    "    elif nivel == 3:\n",
    "        # Subt√≠tulo secundario - Nivel 3\n",
    "        titulo = doc.add_heading(level=3)\n",
    "        run = titulo.add_run(texto)\n",
    "        run.font.name = 'Lora'\n",
    "        run.font.size = Pt(11)\n",
    "        run.font.color.rgb = COLOR_SUBTITULO\n",
    "        run.font.italic = True\n",
    "        titulo.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
    "        titulo.paragraph_format.space_before = Pt(10)\n",
    "        titulo.paragraph_format.space_after = Pt(4)\n",
    "\n",
    "    else:\n",
    "        # Para niveles inferiores\n",
    "        parrafo = doc.add_paragraph(texto)\n",
    "        parrafo.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
    "        run = parrafo.runs[0]\n",
    "        run.font.name = 'Segoe UI Light'\n",
    "        run.font.size = Pt(8)\n",
    "        run.font.underline = True\n",
    "        run.font.bold = True\n",
    "        '''\n",
    "        titulo = doc.add_heading(level=nivel)\n",
    "        run = titulo.add_run(texto)\n",
    "        run.font.name = 'Lora'\n",
    "        run.font.size = Pt(9)\n",
    "        run.font.color.rgb = COLOR_SUBTITULO\n",
    "        titulo.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
    "        titulo.paragraph_format.space_before = Pt(6)\n",
    "        titulo.paragraph_format.space_after = Pt(2)\n",
    "        '''\n",
    "\n",
    "def agregar_parrafo(doc, texto):\n",
    "    parrafo = doc.add_paragraph(texto)\n",
    "    parrafo.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
    "    run = parrafo.runs[0]\n",
    "    run.font.name = 'Segoe UI Light'\n",
    "    run.font.size = Pt(8)\n",
    "\n",
    "def insertar_figura(doc, figura, titulo=None, pie=None):\n",
    "    if titulo:  # Solo agrega t√≠tulo si se proporciona\n",
    "        agregar_titulo(doc, titulo, 3)\n",
    "    imagen_stream = BytesIO()\n",
    "    figura.savefig(imagen_stream, format='png', bbox_inches='tight')\n",
    "    imagen_stream.seek(0)\n",
    "    # Insertar imagen centrada\n",
    "    p = doc.add_paragraph()\n",
    "    run = p.add_run()\n",
    "    run.add_picture(imagen_stream, width=Inches(5.5))\n",
    "    p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "    imagen_stream.close()\n",
    "    # Insertar pie de gr√°fico si se proporciona\n",
    "    if pie:\n",
    "        pie_p = doc.add_paragraph(pie)\n",
    "        pie_p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "        run = pie_p.runs[0]\n",
    "        run.font.name = 'Segoe UI Light'\n",
    "        run.font.size = Pt(6)\n",
    "        run.font.bold = True\n",
    "        run.font.italic = True\n",
    "\n",
    "def set_cell_width(cell, width_inches):\n",
    "    \"\"\"\n",
    "    Establece el ancho de una celda en pulgadas.\n",
    "    \"\"\"\n",
    "    width_twips = int(width_inches * 1440)\n",
    "    cell.width = Inches(width_inches)\n",
    "    tc = cell._tc\n",
    "    tcPr = tc.get_or_add_tcPr()\n",
    "    \n",
    "    # Eliminar cualquier w:tcW anterior\n",
    "    for child in tcPr.findall(qn('w:tcW')):\n",
    "        tcPr.remove(child)\n",
    "\n",
    "    # Crear nuevo elemento de ancho\n",
    "    tcW = OxmlElement('w:tcW')\n",
    "    tcW.set(qn('w:w'), str(width_twips))\n",
    "    tcW.set(qn('w:type'), 'dxa')\n",
    "    tcPr.append(tcW)\n",
    "\n",
    "def insertar_tabla(doc, df, titulo=None):\n",
    "    if titulo:\n",
    "        agregar_titulo(doc, titulo, 3)\n",
    "\n",
    "    tabla = doc.add_table(rows=1, cols=len(df.columns))\n",
    "    tabla.style = 'Table Grid'\n",
    "    tabla.alignment = WD_TABLE_ALIGNMENT.CENTER\n",
    "\n",
    "    ancho_total = 6.0\n",
    "    ancho_columna = ancho_total / len(df.columns)\n",
    "\n",
    "    # Encabezados\n",
    "    hdr_cells = tabla.rows[0].cells\n",
    "    for i, col_name in enumerate(df.columns):\n",
    "        cell = hdr_cells[i]\n",
    "        cell.text = str(col_name)\n",
    "        run = cell.paragraphs[0].runs[0]\n",
    "        run.font.bold = True\n",
    "        run.font.size = Pt(6.5)\n",
    "        run.font.name = 'Segoe UI Light'\n",
    "        set_cell_width(cell, ancho_columna)\n",
    "        # centrar\n",
    "        cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        cell.vertical_alignment      = WD_ALIGN_VERTICAL.CENTER\n",
    "\n",
    "    # Filas de datos\n",
    "    for _, row in df.iterrows():\n",
    "        row_cells = tabla.add_row().cells\n",
    "        for i, value in enumerate(row):\n",
    "            cell = row_cells[i]\n",
    "            cell.text = str(value)\n",
    "            run = cell.paragraphs[0].runs[0]\n",
    "            run.font.size = Pt(7)\n",
    "            set_cell_width(cell, ancho_columna)\n",
    "            # centrar\n",
    "            cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            cell.vertical_alignment      = WD_ALIGN_VERTICAL.CENTER\n",
    "\n",
    "def insertar_tabla_con_merge(doc, df, titulo=None, group_cols=None):\n",
    "    if titulo:\n",
    "        agregar_titulo(doc, titulo, 3)\n",
    "\n",
    "    tabla = doc.add_table(rows=1, cols=len(df.columns))\n",
    "    tabla.style = 'Table Grid'\n",
    "    tabla.alignment = WD_TABLE_ALIGNMENT.CENTER\n",
    "\n",
    "    ancho_total = 6.0\n",
    "    ancho_columna = ancho_total / len(df.columns)\n",
    "\n",
    "    # Encabezados\n",
    "    hdr_cells = tabla.rows[0].cells\n",
    "    for i, col in enumerate(df.columns):\n",
    "        cell = hdr_cells[i]\n",
    "        cell.text = str(col)\n",
    "        run = cell.paragraphs[0].runs[0]\n",
    "        run.font.bold = True\n",
    "        run.font.size = Pt(6.5)\n",
    "        run.font.name = 'Segoe UI Light'\n",
    "        # Anchos\n",
    "        set_cell_width(cell, ancho_columna)\n",
    "        # Centrado horizontal y vertical\n",
    "        cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "\n",
    "    # Filas de datos\n",
    "    for _, row in df.iterrows():\n",
    "        row_cells = tabla.add_row().cells\n",
    "        for i, val in enumerate(row):\n",
    "            cell = row_cells[i]\n",
    "            cell.text = str(val)\n",
    "            run = cell.paragraphs[0].runs[0]\n",
    "            run.font.size = Pt(7)\n",
    "            set_cell_width(cell, ancho_columna)\n",
    "            # Centrado horizontal y vertical\n",
    "            cell.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "\n",
    "    # Merge de grupos (igual que antes)‚Ä¶\n",
    "    if group_cols:\n",
    "        col2idx = {col: idx for idx, col in enumerate(df.columns)}\n",
    "        sizes = OrderedDict()\n",
    "        prev_key = None\n",
    "        for key_vals in df[group_cols].itertuples(index=False, name=None):\n",
    "            if key_vals == prev_key:\n",
    "                sizes[key_vals] += 1\n",
    "            else:\n",
    "                sizes[key_vals] = 1\n",
    "                prev_key = key_vals\n",
    "\n",
    "        current_row = 1\n",
    "        for key_vals, size in sizes.items():\n",
    "            if size > 1:\n",
    "                for col in group_cols:\n",
    "                    c_idx = col2idx[col]\n",
    "                    start = tabla.cell(current_row, c_idx)\n",
    "                    end   = tabla.cell(current_row + size - 1, c_idx)\n",
    "                    # Vaciar intermedias y merge\n",
    "                    for r in range(current_row + 1, current_row + size):\n",
    "                        tabla.cell(r, c_idx).text = ''\n",
    "                    start.merge(end)\n",
    "                    # Aseguramos que la celda fusionada mantenga el centrado\n",
    "                    start.paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                    start.vertical_alignment = WD_ALIGN_VERTICAL.CENTER\n",
    "            current_row += size\n",
    "\n",
    "    return tabla\n",
    "\n",
    "def insertar_salto_pagina(doc):\n",
    "    doc.add_page_break()\n",
    "\n",
    "def agregar_vi√±etas(doc, items, nivel=1, espacio_antes=Pt(4), espacio_despues=Pt(4)):\n",
    "    \"\"\"\n",
    "    Inserta una lista usando guiones '-' como vi√±etas.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Objeto python-docx Document.\n",
    "    items : list de str\n",
    "        Cada cadena ser√° un √≠tem de la lista.\n",
    "    nivel : int, opcional (por defecto=1)\n",
    "        Nivel de sangr√≠a (1 = vi√±etas principales, 2 = sub-vi√±etas, etc.).\n",
    "    espacio_antes : Pt, opcional\n",
    "        Espacio antes de cada √≠tem.\n",
    "    espacio_despues : Pt, opcional\n",
    "        Espacio despu√©s de cada √≠tem.\n",
    "    \"\"\"\n",
    "    indent_por_nivel = Pt(12)  # 12pt de sangr√≠a por nivel\n",
    "\n",
    "    for texto in items:\n",
    "        # Preparo el p√°rrafo con indentaci√≥n\n",
    "        p = doc.add_paragraph()\n",
    "        p.paragraph_format.space_before = espacio_antes\n",
    "        p.paragraph_format.space_after = espacio_despues\n",
    "        # Sangrar seg√∫n nivel, a la izquierda\n",
    "        p.paragraph_format.left_indent = indent_por_nivel * (nivel - 1)\n",
    "\n",
    "        # Agregar el run con gui√≥n + texto\n",
    "        run = p.add_run(f\"- {texto}\")\n",
    "        run.font.name = 'Segoe UI Light'\n",
    "        run.font.size = Pt(8)\n",
    "        # Alineaci√≥n por defecto (izquierda)\n",
    "        p.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
    "\n",
    "def insertar_en_posicion(doc, funcion_contenido, *args, posicion='final', **kwargs):\n",
    "    \"\"\"\n",
    "    Inserta contenido generado por una funci√≥n en una posici√≥n espec√≠fica del documento.\n",
    "\n",
    "    Par√°metros\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Documento principal.\n",
    "    funcion_contenido : function\n",
    "        Funci√≥n que recibe un doc y otros par√°metros, y agrega contenido (p√°rrafo, t√≠tulo, etc.).\n",
    "    *args, **kwargs :\n",
    "        Argumentos para pasar a la funci√≥n.\n",
    "    posicion : str\n",
    "        'inicio', 'final' o 'index:<n>' para insertar en una posici√≥n concreta.\n",
    "    \"\"\"\n",
    "    # Crear documento temporal con el contenido a insertar\n",
    "    doc_temp = Document()\n",
    "    funcion_contenido(doc_temp, *args, **kwargs)\n",
    "\n",
    "    # Extraer elementos del cuerpo\n",
    "    elementos_temp = list(doc_temp.element.body)\n",
    "\n",
    "    # Insertar al inicio, final o √≠ndice\n",
    "    body = doc.element.body\n",
    "\n",
    "    if posicion == 'inicio':\n",
    "        for elem in reversed(elementos_temp):\n",
    "            body.insert(0, elem)\n",
    "    elif posicion == 'final':\n",
    "        for elem in elementos_temp:\n",
    "            body.append(elem)\n",
    "    elif posicion.startswith('index:'):\n",
    "        idx = int(posicion.split(':')[1])\n",
    "        for i, elem in enumerate(elementos_temp):\n",
    "            body.insert(idx + i, elem)\n",
    "    else:\n",
    "        raise ValueError(\"La posici√≥n debe ser 'inicio', 'final' o 'index:<n>'\")\n",
    "\n",
    "def insertar_indice(doc, titulo=\"√çndice\"):\n",
    "    # T√≠tulo del √≠ndice\n",
    "    agregar_titulo(doc, titulo, 1)\n",
    "\n",
    "    # P√°rrafo donde ir√° la tabla de contenido\n",
    "    p = doc.add_paragraph()\n",
    "    run = p.add_run()\n",
    "\n",
    "    # Agregar campo TOC\n",
    "    fldChar1 = OxmlElement('w:fldChar')\n",
    "    fldChar1.set(qn('w:fldCharType'), 'begin')\n",
    "\n",
    "    instrText = OxmlElement('w:instrText')\n",
    "    instrText.set(qn('xml:space'), 'preserve')\n",
    "    instrText.text = r'TOC \\o \"1-3\" \\h \\z \\u'\n",
    "\n",
    "    fldChar2 = OxmlElement('w:fldChar')\n",
    "    fldChar2.set(qn('w:fldCharType'), 'separate')\n",
    "\n",
    "    fldChar3 = OxmlElement('w:fldChar')\n",
    "    fldChar3.set(qn('w:fldCharType'), 'end')\n",
    "\n",
    "    run._r.append(fldChar1)\n",
    "    run._r.append(instrText)\n",
    "    run._r.append(fldChar2)\n",
    "    run._r.append(fldChar3)\n",
    "\n",
    "    # Estilo\n",
    "    p.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT\n",
    "    p.paragraph_format.space_after = Pt(6)\n",
    "\n",
    "def agregar_advertencia_actualizacion(doc):\n",
    "    p = doc.add_paragraph()\n",
    "    run = p.add_run(\"‚ö†Ô∏è Al abrir este documento, recuerde actualizar los campos (√≠ndice, referencias cruzadas, etc.).\")\n",
    "    run.font.italic = True\n",
    "    run.font.color.rgb = RGBColor(0x80, 0x00, 0x00)\n",
    "    p.paragraph_format.space_before = Pt(12)\n",
    "\n",
    "def mostrar_contenido(doc):\n",
    "    print(\"√çndice | Tipo   | Contenido resumido\")\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    idx_parrafo = 0\n",
    "    idx_tabla = 0\n",
    "\n",
    "    for i, elem in enumerate(doc.element.body):\n",
    "        tag = elem.tag.split('}')[-1]\n",
    "\n",
    "        if tag == 'p':\n",
    "            parrafo = doc.paragraphs[idx_parrafo]\n",
    "            texto = parrafo.text.strip().replace('\\n', ' ')\n",
    "            print(f\"{i:<6} | P√°rrafo | '{texto[:60]}'\")\n",
    "            idx_parrafo += 1\n",
    "\n",
    "        elif tag == 'tbl':\n",
    "            print(f\"{i:<6} | Tabla   | [Tabla con {len(doc.tables[idx_tabla].rows)} filas]\")\n",
    "            idx_tabla += 1\n",
    "\n",
    "        else:\n",
    "            print(f\"{i:<6} | Otro    | Etiqueta: {tag}\")\n",
    "    \n",
    "def mostrar_contenido_posicional(doc, buscar=None):\n",
    "    \"\"\"\n",
    "    Si se pasa un texto en `buscar`, tambi√©n devuelve las posiciones donde aparece.\n",
    "    \"\"\"\n",
    "    idx_parrafo = 0\n",
    "    posiciones_encontradas = []\n",
    "\n",
    "    for i, elem in enumerate(doc.element.body):\n",
    "        tag = elem.tag.split('}')[-1]\n",
    "\n",
    "        if tag == 'p':\n",
    "            parrafo = doc.paragraphs[idx_parrafo]\n",
    "            texto = parrafo.text.strip().replace('\\n', ' ')\n",
    "            # print(f\"{i:<6} | P√°rrafo | '{texto[:60]}'\")\n",
    "\n",
    "            if buscar and buscar.lower() in texto.lower():\n",
    "                posiciones_encontradas.append(i)\n",
    "\n",
    "            idx_parrafo += 1\n",
    "\n",
    "    return posiciones_encontradas\n",
    "\n",
    "def reemplazar_parrafo(original: Paragraph, nuevo: Paragraph):\n",
    "    # Reemplaza el elemento XML del p√°rrafo original por el del nuevo\n",
    "    original._element.getparent().replace(original._element, nuevo._element)\n",
    "\n",
    "def numerar_titulos_existentes(doc):\n",
    "    contador = {1: 0, 2: 0, 3: 0}\n",
    "    # Guardar los p√°rrafos a reemplazar (para evitar modificar la lista mientras iteras)\n",
    "    reemplazos = []\n",
    "\n",
    "    for i, parrafo in enumerate(doc.paragraphs):\n",
    "        estilo = parrafo.style.name.strip()\n",
    "        if estilo.startswith(\"Heading\"):\n",
    "            try:\n",
    "                nivel = int(estilo.split()[-1])\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "\n",
    "            if nivel in contador:\n",
    "                contador[nivel] += 1\n",
    "                for deeper in range(nivel + 1, 4):\n",
    "                    contador[deeper] = 0\n",
    "\n",
    "                if nivel == 1:\n",
    "                    numeracion = f\"{contador[1]}.\"\n",
    "                elif nivel == 2:\n",
    "                    numeracion = f\"{contador[1]}.{contador[2]}\"\n",
    "                elif nivel == 3:\n",
    "                    numeracion = f\"{contador[1]}.{contador[2]}.{contador[3]}\"\n",
    "\n",
    "                texto = parrafo.text.strip()\n",
    "                if not texto.startswith(numeracion):\n",
    "                    texto_sin_num = texto\n",
    "                    # Crear un doc temporal para el nuevo t√≠tulo\n",
    "                    doc_temp = Document()\n",
    "                    agregar_titulo(doc_temp, f\"{numeracion} {texto_sin_num}\", nivel)\n",
    "                    nuevo_parrafo = doc_temp.paragraphs[0]\n",
    "                    reemplazos.append((parrafo, nuevo_parrafo))\n",
    "\n",
    "    # Hacer los reemplazos al final para evitar problemas de √≠ndice\n",
    "    for original, nuevo in reemplazos:\n",
    "        reemplazar_parrafo(original, nuevo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_resumen_en_doc(doc, resumen: dict):\n",
    "    # 1. Contexto General del Diagn√≥stico\n",
    "    contexto = resumen.get(\"Contexto General del Diagn√≥stico\")\n",
    "    if contexto:\n",
    "        agregar_titulo(doc, \"Contexto General del Diagn√≥stico\", nivel=2)\n",
    "        agregar_vi√±etas(doc, contexto, nivel=1)\n",
    "\n",
    "    # 2. Hallazgos Clave y Correlaciones Relevantes\n",
    "    hallazgos = resumen.get(\"Hallazgos Clave y Correlaciones Relevantes\")\n",
    "    if hallazgos:\n",
    "        agregar_titulo(doc, \"Hallazgos Clave y Correlaciones Relevantes\", nivel=2)\n",
    "        for categoria, insights in hallazgos.items():\n",
    "            agregar_titulo(doc, categoria, nivel=3)\n",
    "            agregar_vi√±etas(doc, insights, nivel=1)\n",
    "\n",
    "    # 3. Retos Priorizados Identificados\n",
    "    retos = resumen.get(\"Retos Priorizados Identificados\")\n",
    "    if retos:\n",
    "        # convertir lista de dicts a DataFrame\n",
    "        df_retos = pd.DataFrame(retos)\n",
    "        insertar_tabla(doc, df_retos, titulo=\"Retos Priorizados Identificados\")\n",
    "\n",
    "    # 4. Otras Secciones Relevantes (opcional)\n",
    "    otras = resumen.get(\"Otras Secciones Relevantes\")\n",
    "    if otras:\n",
    "        agregar_titulo(doc, \"Otras Secciones Relevantes\", nivel=2)\n",
    "        for seccion, items in otras.items():\n",
    "            agregar_titulo(doc, seccion, nivel=3)\n",
    "            agregar_vi√±etas(doc, items, nivel=1)\n",
    "\n",
    "    # 5. Relevancia del Programa\n",
    "    relevancia = resumen.get(\"Relevancia del Programa\") or resumen.get(\"Relevancia del Programa +Educaci√≥n +Innovaci√≥n\")\n",
    "    if relevancia:\n",
    "        agregar_titulo(doc, \"Relevancia del Programa\", nivel=2)\n",
    "        agregar_vi√±etas(doc, relevancia, nivel=1)\n",
    "    insertar_salto_pagina(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_norm= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intentar convertir los grados a n√∫meros enteros, si falla mantener como string\n",
    "try:\n",
    "    df['grade'] = df['grade'].astype(int)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordernar el DataFrame por tipo de test\n",
    "df['tipo_test_orden'] = df['tipo_test'].apply(ordenar_tipo_test)\n",
    "\n",
    "df['tag_question_orden'] = df['tag_question'].apply(ordenar_tag)\n",
    "\n",
    "df.sort_values(by=['project_id', 'tipo_test_orden','tag_question_orden'], inplace=True)\n",
    "\n",
    "df.drop(columns=['tipo_test_orden', 'tag_question_orden'], inplace=True)\n",
    "\n",
    "df['tipo_test'] = df['tipo_test'].apply(renombrar_tipo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['answer', 'right_answer']: # Limpiar saltos de l√≠nea, retornos de carro y dobles comas en 'answer' y 'right_answer'\n",
    "    df[col] = df[col].str.replace('\\n', '', regex=False)\n",
    "    df[col] = df[col].str.replace('\\r', '', regex=False)\n",
    "    df[col] = df[col].str.replace(',,', ',', regex=False)\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "#df['answer'] = df['answer'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8') # Elimino los acentos y caracteres especiales de las respuestas\n",
    "\n",
    "df['age'] = df['age'].fillna(0).astype(int)  # Convierto edad a numero entero\n",
    "\n",
    "df['question']=df['question'].str.replace('&nbsp;',' ', regex=False) # Elimino los &nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "df['genero'] = df['genero'].map({ 'male': 'Masculino', 'female': 'Femenino', 'unspecified': 'Indefinido' }) # mapeo de genero a espa√±ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasos para clasificar el tipo de pregunta\n",
    "\n",
    "    ## Paso 1: Aplicar la funci√≥n a la columna \"Answer\" para crear una nueva columna \"Tipo de Pregunta\"\n",
    "df['Tipo de Pregunta (por respuesta)'] = df['answer'].apply(clasificar_tipo_pregunta)\n",
    "\n",
    "    ## Paso 2: Crear nuevo dataframe con el tipo por pregunta\n",
    "tipo_por_pregunta = df.groupby('question')['Tipo de Pregunta (por respuesta)'].apply(consolidar_tipo_pregunta).reset_index()\n",
    "tipo_por_pregunta.rename(columns={'Tipo de Pregunta (por respuesta)': 'Tipo de Pregunta'}, inplace=True)\n",
    "\n",
    "    ## Paso 3: unir de vuelta al df original\n",
    "df = df.merge(tipo_por_pregunta, on='question', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agrupar por tag y question, y elegir el texto m√°s frecuente\n",
    "standard_question = df.groupby(['tag_question'])['question'].agg(\n",
    "    lambda x: Counter(x).most_common(1)[0][0]\n",
    ").reset_index()\n",
    "\n",
    "    ## Crear un mapeo autom√°tico\n",
    "mapping = {\n",
    "    row['tag_question']: row['question']\n",
    "    for _, row in standard_question.iterrows()\n",
    "}\n",
    "\n",
    "    ## Aplicar normalizaci√≥n\n",
    "df['question'] = df.apply(normalize_question, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame categ√≥rico tiene 96 filas\n",
      "DataFrame no categ√≥rico tiene 216 filas\n",
      "Procesando respuestas categ√≥ricas...\n",
      "Normalizaci√≥n de respuestas categ√≥ricas completada.\n"
     ]
    }
   ],
   "source": [
    "# Pasos para normalizar las respuestas categ√≥ricas, por si la misma pregunta tiene diferentes respuestas que significan lo mismo\n",
    "\n",
    "df_categorico = df[df['Tipo de Pregunta']=='Categorica'].copy()\n",
    "df_no_categoria = df[df['Tipo de Pregunta']!='Categorica'].copy()\n",
    "\n",
    "print(f\"DataFrame categ√≥rico tiene {len(df_categorico)} filas\")\n",
    "print(f\"DataFrame no categ√≥rico tiene {len(df_no_categoria)} filas\")\n",
    "\n",
    "if len(df_categorico) > 0:\n",
    "    print(\"Procesando respuestas categ√≥ricas...\")\n",
    "    \n",
    "    ## Separar n√∫mero y texto\n",
    "    df_categorico['Number'], df_categorico['Text'] = zip(*df_categorico['answer'].apply(extract_number_text))\n",
    "\n",
    "    ## Agrupar por pregunta y n√∫mero, y elegir el texto m√°s frecuente\n",
    "    standard_texts = df_categorico.groupby(['question', 'Number'])['Text'].agg(\n",
    "        lambda x: Counter(x).most_common(1)[0][0]\n",
    "    ).reset_index()\n",
    "\n",
    "    ## Crear un mapeo autom√°tico\n",
    "    mapping = {\n",
    "        (row['question'], row['Number']): row['Text']\n",
    "        for _, row in standard_texts.iterrows()\n",
    "    }\n",
    "\n",
    "    ## Aplicar normalizaci√≥n\n",
    "    df_categorico['answer'] = df_categorico.apply(normalize_answer, axis=1)\n",
    "\n",
    "    ## borro las columnas number y text\n",
    "    df_categorico.drop(columns=['Number', 'Text'], inplace=True)\n",
    "\n",
    "    ## uno los dataframes\n",
    "    df = pd.concat([df_no_categoria, df_categorico])\n",
    "    print(\"Normalizaci√≥n de respuestas categ√≥ricas completada.\")\n",
    "    \n",
    "else:\n",
    "    print(\"No hay datos categ√≥ricos para procesar. Usando solo datos no categ√≥ricos.\")\n",
    "    df = df_no_categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer_numeric'] = df['answer'].apply(lambda x: extract_number_text(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rango etario\n",
    "df['rango_etario'] = pd.cut(\n",
    "\tdf['age'],\n",
    "\tbins=[0, 5, 11, 17, 24, 34, 54, np.inf],\n",
    "\tlabels=['0-5', '6-11', '12-17', '18-24', '25-34', '35-54', '55+'],\n",
    "\tright=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo=df.copy() # Guardo el dataframe original, lo hago asi porque era un bajon modificar todo el codigo buscando a df\n",
    "\n",
    "\n",
    "df_filtrado = pd.DataFrame() # Crear un nuevo DataFrame a filtrar que luego usare con el nombre df\n",
    "\n",
    "# Recorremos proyecto por proyecto\n",
    "for (pid, pname), grupo in df.groupby(['project_id', 'project_name']):\n",
    "    grupo['respond'] = True\n",
    "    \n",
    "    pivot = grupo.pivot_table(index='student_id',\n",
    "                               columns='tipo_test',\n",
    "                               values='respond',\n",
    "                               fill_value=0)\n",
    "\n",
    "    # Filtrar solo los alumnos que respondieron todos los tests de su proyecto\n",
    "    columnas_test = pivot.columns\n",
    "    alumnos_completos = pivot[pivot[columnas_test].eq(1).all(axis=1)].index\n",
    "\n",
    "    # Filtrar el grupo original\n",
    "    grupo_filtrado = grupo[grupo['student_id'].isin(alumnos_completos)]\n",
    "    \n",
    "    # Agregar al nuevo DataFrame\n",
    "    df_filtrado = pd.concat([df_filtrado, grupo_filtrado], ignore_index=True)\n",
    "\n",
    "df=df_filtrado\n",
    "\n",
    "del df_filtrado # \tborrar df_filtrado para liberar memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time_norm= time.time()\n",
    "time_norm= end_time_norm - start_time_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por proyecto, tipo de test y calcular los inscritos y estudiantes con respuesta\n",
    "df_proyecto = (\n",
    "    df_completo.groupby(['project_id', 'project_name', 'tipo_test'])\n",
    "    .agg(\n",
    "        Activos=('activos_por_proyecto', 'max'),  # M√°ximo de inscritos por proyecto\n",
    "        Evaluados=('student_id', 'nunique'),\n",
    "        Instituciones=('educative_institution', 'nunique'),\n",
    "        age_min=('age', 'min'),\n",
    "        age_max=('age', 'max'),\n",
    "        Salones=('room_id', 'nunique'),\n",
    "        Mujeres=('student_id', lambda x: df_completo.loc[x.index][df_completo.loc[x.index, 'genero'] == 'Femenino']['student_id'].nunique()),\n",
    "        Hombres=('student_id', lambda x: df_completo.loc[x.index][df_completo.loc[x.index, 'genero'] == 'Masculino']['student_id'].nunique()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calcular el porcentaje de respuestas por tipo de test\n",
    "df_proyecto['% Respuestas'] = round((df_proyecto['Evaluados'] / df_proyecto['Activos']) * 100, 1)\n",
    "df_proyecto['% Mujeres']=round(df_proyecto['Mujeres'] / df_proyecto['Evaluados'] * 100, 1)\n",
    "df_proyecto['% Hombres']=round(df_proyecto['Hombres'] / df_proyecto['Evaluados'] * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregar_advertencia_actualizacion(doc)\n",
    "insertar_indice(doc)\n",
    "insertar_salto_pagina(doc)\n",
    "\n",
    "\n",
    "# Agregar t√≠tulo al reporte\n",
    "agregar_titulo(doc, \"Reporte de Respuestas\", 1)\n",
    "## insertar_salto_pagina(doc)\n",
    "\n",
    "\n",
    "# --- Secci√≥n de Introducci√≥n ---\n",
    "agregar_titulo(doc, \"Introducci√≥n\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Datos generales\n",
    "n_proyectos = df_proyecto['project_id'].nunique()\n",
    "tipos_test = sorted(df_proyecto['tipo_test'].unique())\n",
    "n_tipos = len(tipos_test)\n",
    "lista_tests = ', '.join(tipos_test)\n",
    "\n",
    "# P√°rrafo introductorio general\n",
    "intro = (\n",
    "    f\"Este documento presenta un an√°lisis de las respuestas obtenidas en \"\n",
    "    f\"{n_proyectos} proyecto{'s' if n_proyectos > 1 else ''}, considerando \"\n",
    "    f\"{n_tipos} tipo{'s' if n_tipos > 1 else ''} de actividad: {lista_tests}. \"\n",
    "    f\"Se incluyen indicadores de participaci√≥n por proyecto, como el n√∫mero de personas activas, \"\n",
    "    f\"instituciones participantes, g√©nero, rango etario y tasas de respuesta por tipo de prueba.\"\n",
    ")\n",
    "\n",
    "\n",
    "agregar_parrafo(doc, intro)\n",
    "\n",
    "\n",
    "# 2) Detalle por proyecto, consolidando tipos de test\n",
    "for (pid, pname), grupo in df_proyecto.groupby(['project_id', 'project_name']):\n",
    "    activos = grupo['Activos'].max()\n",
    "    instituciones = grupo['Instituciones'].max()\n",
    "    edad_min = grupo['age_min'].min()\n",
    "    edad_max = grupo['age_max'].max()\n",
    "    alumnos_cruzados=df[df['project_id']==pid]['student_id'].nunique()\n",
    "    porcentaje_cruzados=round(alumnos_cruzados*100/activos, 0).astype(int)\n",
    "    salones = grupo['Salones'].max()\n",
    "    \n",
    "    # Resumen por tipo de test en una sola frase\n",
    "    resumen_tests = []\n",
    "    for _, row in grupo.iterrows():\n",
    "        ttest = row['tipo_test']\n",
    "        evaluados = row['Evaluados']\n",
    "        pct_res = row['% Respuestas']\n",
    "        resumen_tests.append(f\"{ttest}: {evaluados} personas ({pct_res:.0f}%)\")\n",
    "        h=row['% Hombres']\n",
    "        m=row['% Mujeres']\n",
    "\n",
    "    resumen_tests_str = ' y en el '.join(resumen_tests)\n",
    "\n",
    "    p√°rrafo= (\n",
    "        f\"Proyecto ¬´{pname}¬ª: cont√≥ con {activos} personas activas en \"\n",
    "        f\"{instituciones} instituci{'ones' if instituciones > 1 else '√≥n'} y {salones} salones. De las personas activas el {h}% son hombres y el {m}% son mujeres. Y ambos generos poseen edades entre \"\n",
    "        f\"{edad_min} y {edad_max} a√±os. Logrando as√≠ alcanzar en el {resumen_tests_str}\"\n",
    "    )\n",
    "\n",
    "    if n_tipos>1:\n",
    "        agregar_parrafo(\n",
    "            doc,\n",
    "            f\"Las respuestas consideradas en el an√°lisis comparativo ser√°n las de aquellas personas que respondieron ambas actividades, siendo un total de {alumnos_cruzados} que representan el {porcentaje_cruzados}% del total de personas activas\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_introduccion = intro + '\\n\\n' + p√°rrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<docx.table.Table at 0x1657d086e40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proyecto['Proyecto'] = df_proyecto['project_name'].astype(str) + ' (' + df_proyecto['project_id'].astype(str) + ')'\n",
    "tabla_proyecto=df_proyecto[['Proyecto', 'tipo_test', 'Activos', 'Evaluados',  '% Hombres' , '% Mujeres', 'Instituciones','Salones', '% Respuestas']].copy()\n",
    "\n",
    "for c in tabla_proyecto.columns:\n",
    "    if '%' in c:\n",
    "        tabla_proyecto[c]=tabla_proyecto[c].astype(int).astype(str) + '%'\n",
    "\n",
    "# Insertar la tabla en el documento\n",
    "insertar_tabla_con_merge(\n",
    "    doc,\n",
    "    tabla_proyecto.rename(\n",
    "        columns={\n",
    "            'tipo_test':'Actividad',\n",
    "            'Activos':'Colaboradores activos',\n",
    "            '% Hombres':'% Evaluados Hombres',\n",
    "            '% Mujeres':'% Evaluadas Mujeres'}),\n",
    "    'Resumen por proyecto y actividad',\n",
    "    group_cols=['Proyecto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "if df_completo['educative_institution'].nunique()>0:\n",
    "    resumen_instituciones = resumen_por_cluster(df_completo,'educative_institution')\n",
    "    if not resumen_instituciones.empty:\n",
    "        # Insertar la tabla en el documento\n",
    "        insertar_tabla(\n",
    "            doc,\n",
    "            resumen_instituciones.rename(\n",
    "                columns={\n",
    "                    'educative_institution': 'Instituci√≥n',\n",
    "                    'Activos': 'Colaboradores activos'}),\n",
    "            f\"Instituciones del proyecto <{pname}>\")\n",
    "\n",
    "if df_completo['grade'].nunique()>0:\n",
    "    resumen_grados = resumen_por_cluster(df_completo,'grade')\n",
    "    \n",
    "    # Ordenar de forma ascendente\n",
    "    resumen_grados  = resumen_grados.sort_values('grade', ascending=True)\n",
    "\n",
    "    if not resumen_grados.empty:\n",
    "        # Insertar la tabla en el documento\n",
    "        insertar_tabla(\n",
    "            doc,\n",
    "            resumen_grados.rename(\n",
    "                columns={\n",
    "                    'grade': 'Grados',\n",
    "                    'Activos': 'Colaboradores activos'}),\n",
    "            f\"Grados del proyecto <{pname}>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficos por Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "start_time_graficos = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def tabla_answer(df_funcion):\n",
    "    '''Esta funcion me sirve para devolver la tabla de respuestas y porcentaje por ansnwer: \n",
    "    Espera un df con la pregunta ya filtrada. Agrupa por tipo de test, answer y realiza los conteos'''\n",
    "\n",
    "    df_base = (\n",
    "                df_funcion\n",
    "                .groupby(['tipo_test', 'answer'])\n",
    "                .size()\n",
    "                .reset_index(name='Conteo')\n",
    "            )\n",
    "            \n",
    "    ### Calcular el total por tipo_test\n",
    "    total_por_test = df_base.groupby('tipo_test', observed=True)['Conteo'].transform('sum')\n",
    "\n",
    "    ### Calcular porcentaje por tipo_test\n",
    "    df_base['porcentaje'] = (df_base['Conteo'] / total_por_test)*100\n",
    "\n",
    "    # Crear tabla resumen\n",
    "    pivot = df_base.pivot_table(\n",
    "        index='answer',\n",
    "        columns='tipo_test',\n",
    "        values='porcentaje'\n",
    "    ).reset_index().fillna(0)\n",
    "\n",
    "    pivot.columns = ['Respuesta'] + [f\"% {col}\" for col in pivot.columns[1:]]\n",
    "\n",
    "    tipo_tests = df_base['tipo_test'].unique()\n",
    "\n",
    "    if len(tipo_tests) == 1:\n",
    "        # Solo un tipo de test: mostrar Conteo y porcentaje\n",
    "        pivot = df_base.groupby(['answer'], observed=True).agg(\n",
    "            Conteo=('Conteo', 'sum'),\n",
    "            Porcentaje=('porcentaje', 'sum')\n",
    "        ).reset_index()\n",
    "        \n",
    "        df_return = pivot.rename(\n",
    "            columns={\n",
    "                'answer':'Opci√≥n',\n",
    "                'Porcentaje':'% Porcentaje sobre el total',\n",
    "                'Conteo':'Cantidad'}).fillna(0)\n",
    "\n",
    "        for c in df_return.columns:\n",
    "            if df_return[c].dtype == 'float64':  # Verificar si la columna es de tipo float\n",
    "                # Primero redondear (para porcentajes) y luego convertir a entero\n",
    "                df_return[c] = df_return[c].round(1)\n",
    "            if '%' in c:\n",
    "                df_return[c] = df_return[c].astype(str) + '%'\n",
    "\n",
    "    else:\n",
    "        # Dos tipos de test: mostrar porcentaje y diferencia\n",
    "        columna_test_1 = f\"% {tipo_tests[0]}\"\n",
    "        columna_test_2 = f\"% {tipo_tests[1]}\"\n",
    "        df_return=pivot.fillna(0)\n",
    "\n",
    "        for c in df_return.columns:\n",
    "            if df_return[c].dtype == 'float64':  # Verificar si la columna es de tipo float\n",
    "                # Primero redondear (para porcentajes) y luego convertir a entero\n",
    "                df_return[c] = df_return[c].apply(lambda x: float(f\"{x:.1f}\"))\n",
    "\n",
    "\n",
    "        df_return['Diferencia (pp)'] = df_return[columna_test_2]- df_return[columna_test_1]\n",
    "\n",
    "        df_return['Diferencia (pp)'] = df_return['Diferencia (pp)'].round(1).astype(str) + ' pp'    \n",
    "        df_return[columna_test_1] = df_return[columna_test_1].astype(str) + ' %'    \n",
    "        df_return[columna_test_2] = df_return[columna_test_2].astype(str) + ' %'    \n",
    "\n",
    "\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def tabla_agrupada(df_funcion, indice):\n",
    "    ''' Esta funcion me sirve para devolver la tabla pivotea de instituciones y answer ''' \n",
    "\n",
    "\n",
    "    # Agrupar y contar respuestas por instituci√≥n, tipo de test y respuesta\n",
    "    df_educative = (\n",
    "        df_funcion\n",
    "        .groupby([indice, 'tipo_test', 'answer'], observed=True)\n",
    "        .size()\n",
    "        .reset_index(name='conteo')\n",
    "    )\n",
    "\n",
    "    # Calcular total por tipo_test dentro de cada instituci√≥n\n",
    "    total_por_test = df_educative.groupby([indice, 'tipo_test'], observed=True)['conteo'].transform('sum')\n",
    "    df_educative['porcentaje'] = (df_educative['conteo'] / total_por_test)\n",
    "\n",
    "    # Detectar cu√°ntos tipos de test hay\n",
    "    tipos = df_educative['tipo_test'].unique()\n",
    "\n",
    "    if len(tipos) == 1:\n",
    "        # Solo un tipo de test: devolver porcentajes por respuesta\n",
    "        pivot = df_educative.pivot_table(\n",
    "            index=indice,\n",
    "            columns='answer',\n",
    "            values='porcentaje',\n",
    "            fill_value=0,\n",
    "            observed=True\n",
    "        ).reset_index()\n",
    "    elif len(tipos) == 2:\n",
    "        # Dos tipos de test: calcular diferencia (variaci√≥n)\n",
    "        t1, t2 = tipos\n",
    "        pivot_pct = df_educative.pivot_table(\n",
    "            index=indice,\n",
    "            columns=['tipo_test', 'answer'],\n",
    "            values='porcentaje',\n",
    "            fill_value=0,\n",
    "            observed=True\n",
    "        )\n",
    "\n",
    "        # Calcular la diferencia entre los dos tests para cada respuesta\n",
    "        variacion = {\n",
    "            answer: (pivot_pct[(t2, answer)] - pivot_pct[(t1, answer)])\n",
    "            for answer in df_educative['answer'].unique()\n",
    "            if (t2, answer) in pivot_pct.columns and (t1, answer) in pivot_pct.columns # Solo calcula la diferencia si ambos tienen datos\n",
    "        }\n",
    "\n",
    "        # Armar DataFrame final con las variaciones\n",
    "        pivot = pd.DataFrame(variacion, index=pivot_pct.index).reset_index()\n",
    "        pivot = pivot.rename(columns={col: f\"{col}\" for col in variacion})\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"La funci√≥n solo soporta 1 o 2 tipos de test.\")\n",
    "    \n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def mapa_calor(data, ind, title=None, use_negative_scale=False):\n",
    "    import matplotlib.ticker as mtick\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "    # Colormaps\n",
    "    neg_colors = [\"#1e88e5\", \"#fdfefe\",\"#f39c12\"]  # rojo ‚Üí blanco ‚Üí verde\n",
    "    pos_colors = [\"#ffffff\", \"#809bce\"]            # blanco ‚Üí celeste\n",
    "\n",
    "    \n",
    "    if use_negative_scale:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom_cmap_neg\", neg_colors)\n",
    "        vmin, vmax = -1, 1\n",
    "        norm = SymLogNorm(linthresh=0.01, vmin=vmin, vmax=vmax)\n",
    "        suffix = \"pp\"\n",
    "    else:\n",
    "        cmap = LinearSegmentedColormap.from_list(\"custom_cmap_pos\", pos_colors)\n",
    "        vmin, vmax = 0, 1\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "        suffix = \"%\"\n",
    "    \n",
    "    # Pivot original\n",
    "    data_pivot = tabla_agrupada(data, indice=ind).set_index(ind)\n",
    "    \n",
    "    # Crear DF de anotaciones: multiplicar por 100, redondear 1 dec, y a√±adir sufijo\n",
    "    annot_df = (data_pivot * 100).round(1).astype(str) + suffix\n",
    "\n",
    "    # Reemplazar los ceros por '-'\n",
    "    annot_df = annot_df.where(data_pivot != 0, \"-\")\n",
    "    \n",
    "    altura=len(data_pivot)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, altura*0.40))\n",
    "    sns.heatmap(\n",
    "        data_pivot,\n",
    "        annot=annot_df,\n",
    "        fmt=\"\",\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        cbar_kws={'label': ''},\n",
    "        ax=ax\n",
    "    )\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    \n",
    "    \n",
    "    # Obtener respuesta correcta\n",
    "    right_answer_actual = df_pregunta['right_answer'].dropna().unique()\n",
    "    right_answer_actual = right_answer_actual[0] if len(right_answer_actual) > 0 else None\n",
    "\n",
    "    # Obtener etiquetas originales\n",
    "    x_labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    new_labels = [ajustar_etiquetas(label) for label in x_labels]\n",
    "\n",
    "    # Asignar nuevas etiquetas\n",
    "    ax.set_xticklabels(new_labels)\n",
    "\n",
    "    # Aplicar formato y color\n",
    "    for tick_label, original_label in zip(ax.get_xticklabels(), x_labels):\n",
    "        tick_label.set_rotation(45)\n",
    "        tick_label.set_horizontalalignment('right')\n",
    "        tick_label.set_fontsize(9)\n",
    "\n",
    "        if original_label == right_answer_actual:\n",
    "            tick_label.set_color('#ff8562')  # Naranja\n",
    "            tick_label.set_weight('bold')  # Set text to bold\n",
    "        else:\n",
    "            tick_label.set_color('black')    # Default\n",
    "\n",
    "    \n",
    "    plt.title(title or \"\", fontsize=12, pad=20)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "    # Colorbar en %\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "    cbar.set_ticks([vmin, 0, vmax])\n",
    "\n",
    "    # Insertar en el documento\n",
    "    insertar_figura(doc, plt)\n",
    "    plt.close()\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def generar_analisis_categorico(df_grouped):\n",
    "    grupos = df_grouped['tipo_test'].unique()\n",
    "    n_grupos = len(grupos)\n",
    "    analisis = []\n",
    "    \n",
    "    # Introducci√≥n adaptable\n",
    "    if n_grupos == 1:\n",
    "        analisis.append(\"El gr√°fico muestra la distribuci√≥n porcentual y nominal de respuestas. \")\n",
    "    else:\n",
    "        analisis.append(\"El gr√°fico compara la distribuci√≥n porcentual y nominal de respuestas entre grupos. \")\n",
    "    \n",
    "    # An√°lisis por grupo (si hay m√°s de 1)\n",
    "    if n_grupos > 0:\n",
    "        for grupo in grupos:\n",
    "            df_grupo = df_grouped[df_grouped['tipo_test'] == grupo]\n",
    "            if not df_grupo.empty:\n",
    "                max_row = df_grupo.loc[df_grupo['%'].idxmax()]\n",
    "                analisis.append(\n",
    "                    f\"En la actividad {grupo}, la opci√≥n m√°s frecuente fue '{max_row['Respuestas']}' \"\n",
    "                    f\"({max_row['%']:.1f}%). \"\n",
    "                )\n",
    "    \n",
    "    # Comparativa solo si hay 2 grupos\n",
    "    if n_grupos == 2:\n",
    "        diferencias = []\n",
    "        for Respuestas in df_grouped['Respuestas'].unique():\n",
    "            vals = df_grouped[df_grouped['Respuestas'] == Respuestas]['%'].values\n",
    "            if len(vals) == 2:\n",
    "                diferencia = abs(vals[0] - vals[1])\n",
    "                diferencias.append((diferencia, Respuestas))\n",
    "        \n",
    "        if diferencias:\n",
    "            max_diff = max(diferencias, key=lambda x: x[0])\n",
    "            analisis.append(\n",
    "                f\"La mayor diferencia entre grupos ocurre en '{max_diff[1]}' \"\n",
    "                f\"({max_diff[0]:.1f} pp). \"\n",
    "            )\n",
    "    \n",
    "    # Menci√≥n de categor√≠a menos seleccionada (solo si aplica)\n",
    "    if not df_grouped.empty:\n",
    "        min_global = df_grouped.loc[df_grouped['%'].idxmin()]\n",
    "        analisis.append(\n",
    "            f\"La opci√≥n menos seleccionada fue '{min_global['Respuestas']}' \"\n",
    "            f\"({min_global['%']:.1f}%). \"\n",
    "        )\n",
    "    \n",
    "    # Tama√±o muestral siempre\n",
    "    # total_respuestas = df_grouped['Conteo'].sum()\n",
    "    # analisis.append(f\"Base: {total_respuestas} respuestas.\")\n",
    "    \n",
    "    return \" \".join(analisis).replace(\"  \", \" \")  # Limpiar dobles espacios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "conclusion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "##\n",
    "agregar_titulo(doc, \"An√°lisis realizado por pregunta\", 2)\n",
    "\n",
    "agregar_parrafo(doc, \"Para poder entender c√≥mo se distribuyeron las respuestas primero ver√°s gr√°ficos de barras, que son columnas que muestran cu√°ntas personas respondieron cada opci√≥n. Luego debajo de cada gr√°fico encontrar√°s una tabla con n√∫meros que muestran los mismos datos, pero con cifras exactas. Es como un resumen r√°pido de lo que ves en el gr√°fico de arriba.\")\n",
    "\n",
    "if df.tipo_test.nunique()>1 and len(lista_graficos)>0:\n",
    "\n",
    "    agregar_parrafo(doc, f\"Siguiendo por los mapas de calor, que parecen cuadros de colores. Imag√≠nate un sem√°foro pero con m√°s tonos: muestra c√≥mo vari√≥ el porcentaje de respuestas entre la primera y la segunda actividad. Los colores indican el tipo de cambio. Por ejemplo, si separamos las respuestas por edad, puedes ver al instante si los j√≥venes respondieron diferente que los adultos mayores.\")\n",
    "    agregar_vi√±etas(doc, [\"Los tonos calientes muestran un aumento en la proporci√≥n de respuestas.\",\n",
    "    \"Los tonos frios indican una disminuci√≥n.\",\n",
    "    \"Los colores m√°s claros representan cambios peque√±os, y los m√°s oscuros, cambios m√°s grandes.\"])\n",
    "\n",
    "else:\n",
    "\n",
    "    agregar_parrafo(doc, f\"Siguiendo por los mapas de calor, que parecen cuadros de colores. Los colores claros significan pocas respuestas y los colores oscuros significan muchas respuestas. Estos mapas te ayudan a ver patrones r√°pidamente.\")\n",
    "    agregar_parrafo(doc, f\"Por ejemplo, si separamos las respuestas por edad, puedes ver al instante si los j√≥venes respondieron diferente que los adultos mayores.\")\n",
    "\n",
    "\n",
    "df['tipo_test_orden'] = df['tipo_test'].apply(ordenar_tipo_test)\n",
    "\n",
    "df['tag_question_orden'] = df['tag_question'].apply(ordenar_tag)\n",
    "\n",
    "lista_preguntas=df[['tipo_test_orden','tag_question_orden', 'question', 'Tipo de Pregunta']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "lista_preguntas.sort_values(by=['tipo_test_orden','tag_question_orden'], inplace=True)\n",
    "\n",
    "lista_preguntas.drop(columns=['tipo_test_orden', 'tag_question_orden'], inplace=True)\n",
    "\n",
    "\n",
    "# 2) Explode del array de respuestas solo para preguntas de tipo \"Categorica Multiseleccion\"\n",
    "mask_multi = df['Tipo de Pregunta'] == 'Categorica Multiseleccion'\n",
    "df_multi = df[mask_multi].copy()\n",
    "df_otros = df[~mask_multi].copy()\n",
    "\n",
    "# Explode y split solo para multiselecci√≥n\n",
    "df_multi = df_multi.explode('answer')\n",
    "df_multi = (\n",
    "    df_multi\n",
    "    .assign(\n",
    "        answer=df_multi['answer'].str.split(r'[;](?=\\s*\\d+\\.)|[;](?!\\s*\\d+\\.)')\n",
    "    )\n",
    "    .explode('answer')\n",
    ")\n",
    "df_multi['answer'] = df_multi['answer'].str.strip()\n",
    "\n",
    "# Unir de nuevo\n",
    "df = pd.concat([df_multi, df_otros], ignore_index=True)\n",
    "\n",
    "df = df.drop_duplicates(subset=['student_id', 'question', 'tipo_test', 'answer'])\n",
    "# recorrer question de la lista de preguntas, si el tipo de pregunta es categorica hacer un grafico si no hacer otro\n",
    "h=0\n",
    "for i in range(len(lista_preguntas)):\n",
    "    conclusion_pregunta=[]\n",
    "\n",
    "    h=h+1\n",
    "    pregunta = lista_preguntas['question'].iloc[i]\n",
    "    tipo_pregunta = lista_preguntas['Tipo de Pregunta'].iloc[i]\n",
    "\n",
    "    ## Filtrar el DataFrame por la pregunta actual\n",
    "    df_pregunta = df[df['question'] == pregunta].copy()\n",
    "\n",
    "    ninstituciones=df_pregunta['educative_institution'].nunique()\n",
    "    proyectos = df_pregunta[['project_name', 'project_id']].drop_duplicates()\n",
    "    proyectos_str = ', '.join([f\"{row['project_name']} ({row['project_id']})\" for _, row in proyectos.iterrows()])\n",
    "    pie_texto = f\"El grafico incluye respuestas de: {proyectos_str}\"\n",
    "\n",
    "    if tipo_pregunta != 'Abierta':\n",
    "        ### Aqu√≠ puedes agregar la l√≥gica para crear gr√°ficos de barras\n",
    "\n",
    "        ### Agrupar por respuesta y tipo_test\n",
    "        df_base = (\n",
    "            df_pregunta\n",
    "            .groupby(['tipo_test', 'answer'])\n",
    "            .size()\n",
    "            .reset_index(name='Conteo')\n",
    "        )\n",
    "\n",
    "        ### Calcular el total por tipo_test\n",
    "        total_por_test = df_base.groupby('tipo_test')['Conteo'].transform('sum')\n",
    "\n",
    "        ### Calcular porcentaje por tipo_test\n",
    "        df_base['%'] = df_base['Conteo'] *100 / total_por_test \n",
    "        \n",
    "        ### Orden l√≥gico de las categor√≠as\n",
    "        categorias = df_base['answer'].dropna().unique()\n",
    "        try:\n",
    "            categorias_ordenadas = sorted(\n",
    "                categorias,\n",
    "                key=lambda x: (extraer_numero(x) if extraer_numero(x) is not None else float('inf'),\n",
    "                            str(x).lower())\n",
    "            )\n",
    "        except Exception:\n",
    "            categorias_ordenadas = sorted(categorias)\n",
    "        \n",
    "        # Paleta de colores\n",
    "        if df_base['tipo_test'].nunique() == 1:\n",
    "            paleta= ['#9FDEF1']  # Celeste\n",
    "        else:\n",
    "            paleta = ['#9FDEF1', '#FFB500']  # Celeste y Naranja\n",
    "\n",
    "        ## Plot\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        ax = sns.barplot(\n",
    "            data=df_base,\n",
    "            x='answer',\n",
    "            y='%',\n",
    "            hue='tipo_test',\n",
    "            order=categorias_ordenadas,\n",
    "            palette=paleta # Celeste and Naranja colors\n",
    "        )\n",
    "\n",
    "        ### Etiquetas X\n",
    "        etiquetas_ajustadas = [ajustar_etiquetas(str(cat)) for cat in categorias_ordenadas]\n",
    "\n",
    "        # Asegurar que el n√∫mero de categor√≠as coincide con los ticks\n",
    "        ax.set_xticks(range(len(categorias_ordenadas)))\n",
    "        ax.set_xticklabels(etiquetas_ajustadas)\n",
    "\n",
    "        # Aplicar formato y color a cada etiqueta\n",
    "        right_answer_actual = df_pregunta['right_answer'].dropna().unique()\n",
    "        right_answer_actual = right_answer_actual[0] if len(right_answer_actual) > 0 else None\n",
    "\n",
    "        for tick_label, categoria in zip(ax.get_xticklabels(), categorias_ordenadas):\n",
    "            tick_label.set_rotation(45)\n",
    "            tick_label.set_horizontalalignment('right')\n",
    "            tick_label.set_fontsize(10)\n",
    "            \n",
    "            if categoria == right_answer_actual:\n",
    "                tick_label.set_color('#ff8562')  # Naranja\n",
    "                tick_label.set_weight('bold')  # Set text to bold\n",
    "            else:\n",
    "                tick_label.set_color('black')    # Default\n",
    "\n",
    "        \n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(\"\")\n",
    "        ### leyenda como test\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "        ### 1) Leyenda centrada abajo, fuera del √°rea de datos\n",
    "        ax.legend(\n",
    "            loc='best',\n",
    "            ncol=len(df_base['tipo_test'].unique()),\n",
    "            frameon=False,\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "        ### Agregar Conteo y porcentaje sobre cada barra\n",
    "        for bar, (_, fila) in zip(ax.patches, df_base.iterrows()):\n",
    "            altura = bar.get_height()\n",
    "            if altura > 0:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    altura + 1,\n",
    "                    f\"{int(fila['Conteo'])}\\n({altura:.1f}%)\",\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    fontsize=8,\n",
    "                    rotation=0\n",
    "                )\n",
    "\n",
    "        ### T√≠tulo\n",
    "        titulo = f\"Distribuci√≥n de respuestas para la pregunta: {pregunta}\"\n",
    "        plt.title(ajustar_titulo(titulo, 44, 120, 3), fontsize=10, pad=30)\n",
    "        plt.yticks([])\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=1)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        \n",
    "        #Word\n",
    "        df_base=df_base.rename(columns={'answer':'Respuestas'})\n",
    "\n",
    "        agregar_titulo(doc, f\"{pregunta}\", 3)\n",
    "\n",
    "        # Generar an√°lisis autom√°tico\n",
    "        if IA is True:\n",
    "            texto_analisis = OA.analyze_dataframe(df_base,pregunta)\n",
    "            conclusion_pregunta.append(texto_analisis)\n",
    "        else:\n",
    "            texto_analisis = generar_analisis_categorico(df_base)\n",
    "\n",
    "        agregar_parrafo(doc, texto_analisis)\n",
    "\n",
    "        # Insertar grafico\n",
    "        insertar_figura(doc, plt, pie=pie_texto)\n",
    "        \n",
    "\n",
    "        agregar_parrafo(doc, \"En la siguiente tabla dispone del resumen del grafico en formato tabular\")\n",
    "        insertar_tabla(doc, tabla_answer(df_pregunta))\n",
    "        \n",
    "        \n",
    "        if df.tipo_test.nunique()>1 and len(lista_graficos)>0:\n",
    "            for c in lista_graficos:\n",
    "                if c in df_pregunta.columns and df_pregunta[c].notna().any():\n",
    "                    variable=mapeo_variables.get(c, c)\n",
    "\n",
    "                    texto_base=f\"Como vario la entrada y la salida en puntos porcentuales (pp) las respuestas por {variable.lower()} en la pregunta:\"\n",
    "                    texto_mas_pregunta=f\"{texto_base} {pregunta}\"\n",
    "\n",
    "                    agregar_titulo(doc, f\"Observamos por {variable}:\", 4)\n",
    "                    \n",
    "                    if IA is True:\n",
    "                        df_analisis_mapa=tabla_agrupada(df_pregunta, c)\n",
    "                        texto_analisis_mapa=OA.analyze_dataframe(df_analisis_mapa, texto_mas_pregunta, matriz=True)\n",
    "                        conclusion_pregunta.append(texto_analisis_mapa)\n",
    "                        agregar_parrafo(doc, texto_analisis_mapa)\n",
    "                    \n",
    "                    mapa_calor(df_pregunta, c, ajustar_titulo(texto_mas_pregunta, len(texto_base), 120, 3), True)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for c in lista_graficos:\n",
    "                if c in df_pregunta.columns and df_pregunta[c].notna().any():\n",
    "                    variable=mapeo_variables.get(c, c)\n",
    "\n",
    "                    texto_base=f\"¬øC√≥mo se concentraron las respuestas por {variable.lower()}? en la pregunta:\"\n",
    "                    texto_mas_pregunta=f\"{texto_base} {pregunta}\"\n",
    "                    \n",
    "                    agregar_titulo(doc, f\"Observamos por {variable}:\", 4)\n",
    "\n",
    "                    if IA is True:\n",
    "                        df_analisis_mapa=tabla_agrupada(df_pregunta, c)\n",
    "                        texto_analisis_mapa=OA.analyze_dataframe(df_analisis_mapa, texto_mas_pregunta, matriz=True)\n",
    "                        conclusion_pregunta.append(texto_analisis_mapa)\n",
    "                        agregar_parrafo(doc, texto_analisis_mapa)\n",
    "                        \n",
    "                    mapa_calor(df_pregunta, c,  ajustar_titulo(texto_mas_pregunta, len(texto_base), 120, 3))\n",
    "                    \n",
    "        if (IA is True) and (len(conclusion_pregunta)>0): \n",
    "            texto_ai=OA.insight_parcial(conclusion_pregunta, texto_mas_pregunta)\n",
    "            conclusion.append(texto_ai)    \n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        # Si no es categ√≥rica, puedes agregar otra l√≥gica o simplemente pasar\n",
    "        h=h-1\n",
    "        # print(f\"Pregunta Abierta: {pregunta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "end_time_graficos = time.time()\n",
    "tiempo_graficos = end_time_graficos - start_time_graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "if IA is True:\n",
    "    # Paso 1: Insertar t√≠tulo \"Resumen ejecutivo\" antes de la Introducci√≥n\n",
    "    pos_intro = mostrar_contenido_posicional(doc, 'Introducci√≥n')[0]\n",
    "    insertar_en_posicion(doc, agregar_titulo, \"Resumen ejecutivo\", 2, posicion=f'index:{pos_intro}')\n",
    "\n",
    "    # Paso 2: Generar texto resumen con modelo OA y agregarlo antes de la Introducci√≥n\n",
    "    texto_resumen = OA.analyze_list(conclusion, tabla_proyecto, texto_introduccion)\n",
    "    pos_intro = mostrar_contenido_posicional(doc, 'Introducci√≥n')[0]\n",
    "    insertar_en_posicion(doc, agregar_parrafo, texto_resumen, posicion=f'index:{pos_intro}')\n",
    "\n",
    "    # Paso 3: Insertar salto de p√°gina antes de la Introducci√≥n\n",
    "    pos_intro = mostrar_contenido_posicional(doc, 'Introducci√≥n')[0]\n",
    "    insertar_en_posicion(doc, insertar_salto_pagina, posicion=f'index:{pos_intro}')\n",
    "\n",
    "    # Paso 4: Generar JSON estructurado con insights del modelo OA\n",
    "    OA_insight = OA.insight_list(conclusion, tabla_proyecto, texto_introduccion)\n",
    "    match = re.search(r\"\\{.*\\}\", OA_insight, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        resumen = json.loads(json_str)\n",
    "\n",
    "        # Paso 5: Insertar contenido del resumen en la secci√≥n \"Resumen ejecutivo\"\n",
    "        idx_resumen = mostrar_contenido_posicional(doc, buscar=\"REPORTE DE RESPUESTAS\")\n",
    "        if idx_resumen:\n",
    "            insertar_en_posicion(doc, procesar_resumen_en_doc, resumen, posicion=f'index:{idx_resumen[0] + 1}')\n",
    "    \n",
    "            \n",
    "    uso_modelo=pd.DataFrame(OA.registro_tokens)\n",
    "    # Convertir la columna de fecha/hora a tipo datetime\n",
    "    uso_modelo['fecha_hora'] = pd.to_datetime(uso_modelo['fecha_hora'])\n",
    "\n",
    "    # Agrupar el DataFrame actual\n",
    "    resumen_nuevo = uso_modelo.groupby('modelo').agg({\n",
    "        'fecha_hora': 'min',\n",
    "        'input_tokens': 'sum',\n",
    "        'output_tokens': 'sum',\n",
    "        'costo_usd': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    archivo = \"uso_modelo.csv\"\n",
    "\n",
    "    if os.path.exists(archivo):\n",
    "        # Leer el archivo existente\n",
    "        resumen_existente = pd.read_csv(archivo, parse_dates=['fecha_hora'])\n",
    "        # Unir ambos DataFrames\n",
    "        resumen_total = pd.concat([resumen_existente, resumen_nuevo])\n",
    "        # Volver a agrupar para sumar correctamente y conservar la primera fecha\n",
    "        \n",
    "    else:\n",
    "        resumen_total = resumen_nuevo\n",
    "\n",
    "    # Guardar el archivo actualizado\n",
    "    resumen_total.to_csv(archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerar_titulos_existentes(doc)\n",
    "# guardar el documento\n",
    "doc.save(f'{tipo_test} ({project_id}).docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Etapa</th>\n",
       "      <th>Tiempo (segundos)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consulta Athena</td>\n",
       "      <td>15.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalizaci√≥n</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gr√°ficos y Word</td>\n",
       "      <td>33.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>49.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Etapa  Tiempo (segundos)\n",
       "0  Consulta Athena              15.03\n",
       "1    Normalizaci√≥n               0.28\n",
       "2  Gr√°ficos y Word              33.83\n",
       "3            Total              49.14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear tabla de tiempos de ejecuci√≥n\n",
    "tiempos = [\n",
    "    {\"Etapa\": \"Consulta Athena\", \"Tiempo (segundos)\": round(time_consulta, 2)},\n",
    "    {\"Etapa\": \"Normalizaci√≥n\", \"Tiempo (segundos)\": round(time_norm, 2)},\n",
    "    {\"Etapa\": \"Gr√°ficos y Word\", \"Tiempo (segundos)\": round(tiempo_graficos, 2)},\n",
    "    {\"Etapa\": \"Total\", \"Tiempo (segundos)\": round(time_consulta + time_norm + tiempo_graficos, 2)},\n",
    "]\n",
    "df_tiempos = pd.DataFrame(tiempos)\n",
    "display(df_tiempos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
